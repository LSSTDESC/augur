"""Data analysis module.

This module runs the actual analysis of the data that
has been previously generated by the generate module.
At the moment it is a thin-wrapper to cosmosis.

"""

import firecrown
import pathlib
from .generate import firecrown_sanitize
from copy import deepcopy
import numpy as np
import numdifftools as nd
from scipy.interpolate import interp1d, interp2d


def analyze(config):
    """ Analyzes the data, i.e. a thin wrapper to firecrown

    Parameters:
    ----------
    config : dict
        The yaml parsed dictional of the input yaml file
    """

    ana_config = config["analyze"]
    _config, data = firecrown.parse(firecrown_sanitize(ana_config))
    # firecrown.run_cosmosis(_config, data, pathlib.Path(ana_config["cosmosis"]["output_dir"]))
    F_ij = np.loadtxt(pathlib.Path(ana_config["cosmosis"]["output_dir"]) / 'chain.txt')
    # evaluate ell_sys and C_ell_sys from the config
    X = np.loadtxt(config["fisher"]["C_ell_sys_path"])
    ell_sys = X[:, 0]
    C_ell_sys = X[:, 1]
    bias = run_bias(config, F_ij, ell_sys, C_ell_sys)
    np.savetxt(pathlib.Path(config["fisher"]["output_bias"]), bias)


def run_bias(config, F_ij, ell_sys, C_ell_sys):
    """
    Call likelihood and compute relevant derivatives to get
    an estimate of the Fisher bias.

    Parameters:
    -----------
    config : dict
        The yaml parsed dictionary of the input yaml file,
    F_ij : ndarray
        Fisher matrix computed at the maximum likelihood position
        through the calculation of the Hessian of the likelihood.
    ell_sys: ndarray
        Multipoles at which the systematics power spectrum is passed.
    C_ell_sys: ndarray
        Power spectrum of the systematics (evaluated at ell_sys).

    Returns:
    --------
    b_j : ndarray
        Fisher biases (see Biancamaria's work for more details).
    """

    ana_config = config["analyze"]
    _config, data = firecrown.parse(firecrown_sanitize(ana_config))
    # Reference Parameters
    ref_pars = data["parameters"]
    par_names = list(set(list(data["priors"]["data"].keys())) - set(["module"]))
    # Get covariance matrix
    cov = data["two_point"]["data"]["likelihood"].cov

    def C_ell_2pt(x):
        pars = deepcopy(ref_pars)  # To make sure that we start from the same point
        for i in range(len(x)):
            pars[par_names[i]] = x[i]
        # Create cosmology object
        cosmo = firecrown.get_ccl_cosmology(pars)
        # Render tracers
        for _, src in data["two_point"]["data"]["sources"].items():
            src.render(cosmo, params=pars,
                       systematics=data["two_point"]["data"]["systematics"])
        # Render the C_ells
        pred_all = []
        ells_all = []
        n_ells = []
        for name, stat in data["two_point"]["data"]["statistics"].items():
            stat.compute(cosmo, pars, data["two_point"]["data"]["sources"],
                         systematics=data["two_point"]["data"]["systematics"])
            pred_all.append(stat.predicted_statistic_)
            ells = stat.ell_or_theta_
            ells_all.append(ells)
            n_ells.append(len(ells))
        pred_all = np.concatenate(pred_all)
        ells_all = np.concatenate(ells_all)
        ell_max = np.max(ells_all)
        ell_min = np.min(ells_all)
        pred_out = []
        cov_out = []
        ells_out = np.linspace(int(ell_min), int(ell_max),
                               int(ell_max)-int(ell_min)+1)
        print(ells_out)
        # Interpolate to get delta_ell = 1 predictions
        for i in range(len(n_ells)):
            if i < 1:
                min_i = 0
            else:
                min_i = n_ells[i-1]
            max_i = n_ells[i]+min_i
            sp_cls = interp1d(ells_all[min_i:max_i],
                              pred_all[min_i:max_i], fill_value="extrapolate")
            delta_ell_i = np.gradient(ells_all[min_i:max_i])
            # Power spectrum with delta_ell = 1
            pred_out.append(sp_cls(ells_out))
            # Now we need the covariance. Caveat: re-scale by delta_ell!
            for j in range(len(n_ells)):
                if j < 1:
                    min_j = 0
                else:
                    min_j = n_ells[j-1]
                max_j = n_ells[j]+min_j
                delta_ell_j = np.gradient(ells_all[min_j:max_j])
                cov_corr = cov[min_i:max_i, min_j:max_j]*delta_ell_i[:, np.newaxis]
                cov_corr = cov_corr*delta_ell_j[np.newaxis, :]
                sp_cov = interp2d(ells_all[min_i:max_i], ells_all[min_j:max_j], cov_corr.T)
                cov_out.append(sp_cov(ells_out, ells_out))

        return pred_out, cov_out, ells_out, n_ells

    x0 = [data["parameters"][kk] for kk in par_names]
    # We need the multipoles at which we have the data-vectors
    # we are assuming smooth power spectra and top-hat windows
    C_ell_ref, Cov_ref, ells_ref, n_ells = C_ell_2pt(x0)
    n_combs = len(n_ells)

    print(C_ell_ref, Cov_ref, n_combs)
